{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e089410",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
    "\n",
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d8dbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:55.803857Z",
     "iopub.status.busy": "2022-07-31T02:32:55.803417Z",
     "iopub.status.idle": "2022-07-31T02:32:56.504212Z",
     "shell.execute_reply": "2022-07-31T02:32:56.503478Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2885d",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80fe2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.507830Z",
     "iopub.status.busy": "2022-07-31T02:32:56.507438Z",
     "iopub.status.idle": "2022-07-31T02:32:56.518747Z",
     "shell.execute_reply": "2022-07-31T02:32:56.518155Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d2fa6",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b0261e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.521551Z",
     "iopub.status.busy": "2022-07-31T02:32:56.521348Z",
     "iopub.status.idle": "2022-07-31T02:32:56.528208Z",
     "shell.execute_reply": "2022-07-31T02:32:56.527619Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227d24b",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d62889d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.530996Z",
     "iopub.status.busy": "2022-07-31T02:32:56.530638Z",
     "iopub.status.idle": "2022-07-31T02:32:56.536985Z",
     "shell.execute_reply": "2022-07-31T02:32:56.536389Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b254c7b",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bdd6df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.539741Z",
     "iopub.status.busy": "2022-07-31T02:32:56.539403Z",
     "iopub.status.idle": "2022-07-31T02:32:56.545387Z",
     "shell.execute_reply": "2022-07-31T02:32:56.544765Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b03328d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MLP' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\THC\\自动化所\\资料\\d2l-zh-pytorch\\5 chapter_deep-learning-computation\\read-write.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/THC/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%80/%E8%B5%84%E6%96%99/d2l-zh-pytorch/5%20chapter_deep-learning-computation/read-write.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'MLP' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bb902",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c11c100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.549285Z",
     "iopub.status.busy": "2022-07-31T02:32:56.548944Z",
     "iopub.status.idle": "2022-07-31T02:32:56.553472Z",
     "shell.execute_reply": "2022-07-31T02:32:56.552867Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a66e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1717,  0.0988, -0.0463,  ..., -0.0093, -0.1791,  0.0055],\n",
       "                      [-0.1778,  0.1721,  0.1688,  ...,  0.1574, -0.0777, -0.0364],\n",
       "                      [ 0.0782, -0.1476, -0.0820,  ...,  0.0867,  0.1096, -0.1409],\n",
       "                      ...,\n",
       "                      [-0.1027,  0.0609, -0.0863,  ...,  0.0207,  0.0844, -0.0231],\n",
       "                      [-0.1114,  0.0471,  0.1629,  ...,  0.0673, -0.1120,  0.0263],\n",
       "                      [-0.1205,  0.0004, -0.1953,  ...,  0.1624, -0.0443, -0.0871]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.0200,  0.0019,  0.0875,  0.0009,  0.0428,  0.0407,  0.1420,  0.1980,\n",
       "                      -0.0250,  0.0400, -0.1103, -0.1635, -0.1392,  0.1751, -0.0538,  0.0251,\n",
       "                       0.1406,  0.0753,  0.1283, -0.1726,  0.1860, -0.1585, -0.1286, -0.0137,\n",
       "                       0.0658,  0.1336, -0.1503,  0.1148, -0.0181, -0.0250, -0.1848, -0.1574,\n",
       "                      -0.1870, -0.0895, -0.1547, -0.0512, -0.1421,  0.0656,  0.1847, -0.0050,\n",
       "                       0.1919,  0.0441,  0.0017,  0.0933,  0.2078,  0.2176,  0.1576,  0.1400,\n",
       "                      -0.0761, -0.1423,  0.0532,  0.1178,  0.1856,  0.0607,  0.1368,  0.1902,\n",
       "                       0.2129, -0.1535,  0.0975,  0.2052,  0.0131, -0.1229, -0.1285,  0.1460,\n",
       "                       0.0460, -0.0961, -0.1261, -0.0856, -0.1007,  0.0288, -0.0423, -0.0138,\n",
       "                      -0.2048, -0.1315,  0.2171,  0.1573,  0.1602,  0.1954,  0.0513, -0.0122,\n",
       "                       0.0971,  0.1468,  0.2089,  0.0743,  0.1337, -0.1956, -0.0083, -0.1071,\n",
       "                       0.0618, -0.2060, -0.1137, -0.0962,  0.1789, -0.1741, -0.0272, -0.1892,\n",
       "                       0.0598, -0.1581,  0.1609,  0.0907, -0.1828, -0.0647,  0.1470,  0.1955,\n",
       "                       0.1333,  0.1828, -0.1882, -0.0194, -0.0015,  0.1486, -0.1084, -0.1426,\n",
       "                       0.1274, -0.0562,  0.1129,  0.1818,  0.1503,  0.0855,  0.0484, -0.0884,\n",
       "                      -0.2152,  0.0801,  0.0111,  0.0579,  0.2173,  0.1463,  0.1132, -0.0984,\n",
       "                      -0.0876, -0.1882,  0.0453, -0.1755,  0.0241,  0.1210,  0.1974, -0.1635,\n",
       "                       0.1546,  0.0252, -0.1965,  0.0245, -0.2161,  0.0954, -0.1786,  0.1889,\n",
       "                       0.0374,  0.0677, -0.0696, -0.2152,  0.1796,  0.0595,  0.1872,  0.0695,\n",
       "                       0.0752, -0.0167, -0.1445,  0.1554,  0.0060,  0.0202, -0.0861,  0.1529,\n",
       "                      -0.1204, -0.0039, -0.0628, -0.1034,  0.0195,  0.0133,  0.0212,  0.0191,\n",
       "                       0.1972,  0.2164,  0.1784,  0.2024, -0.0987, -0.1097,  0.0315, -0.0855,\n",
       "                       0.0858,  0.0789, -0.0032,  0.2215, -0.1024, -0.1251,  0.0484, -0.1762,\n",
       "                      -0.0439,  0.0845, -0.0083, -0.0207, -0.0089, -0.0356,  0.0011, -0.0586,\n",
       "                       0.0943, -0.0839,  0.1680,  0.1031,  0.2193,  0.0643,  0.2100, -0.1274,\n",
       "                       0.1407,  0.1988,  0.0181, -0.1980, -0.1426,  0.0737, -0.2083,  0.2112,\n",
       "                      -0.1284, -0.1695, -0.1825, -0.1229,  0.0105,  0.0729, -0.0771,  0.2177,\n",
       "                       0.0549,  0.0286, -0.1527,  0.2118,  0.0838,  0.1390, -0.0622, -0.0097,\n",
       "                      -0.1570, -0.0066, -0.0624, -0.0012,  0.0081,  0.2072, -0.0945,  0.0264,\n",
       "                      -0.1417, -0.0152,  0.1253,  0.0199,  0.1145,  0.0222,  0.1997,  0.1490,\n",
       "                      -0.1157, -0.0881,  0.0322, -0.1676, -0.0624,  0.1942, -0.1535, -0.0953,\n",
       "                       0.2178,  0.0791,  0.0484,  0.0433, -0.2035, -0.1952, -0.0985, -0.1198])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.0246,  0.0035, -0.0622,  ...,  0.0234,  0.0457, -0.0020],\n",
       "                      [ 0.0307,  0.0537, -0.0467,  ...,  0.0062,  0.0484,  0.0486],\n",
       "                      [ 0.0328,  0.0476,  0.0143,  ...,  0.0529, -0.0114,  0.0581],\n",
       "                      ...,\n",
       "                      [-0.0474, -0.0523, -0.0038,  ...,  0.0392, -0.0457,  0.0284],\n",
       "                      [-0.0523, -0.0275,  0.0370,  ..., -0.0378,  0.0394, -0.0379],\n",
       "                      [-0.0150,  0.0015,  0.0097,  ..., -0.0078, -0.0407,  0.0127]])),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0598,  0.0422, -0.0175,  0.0102, -0.0612, -0.0120,  0.0448, -0.0163,\n",
       "                      -0.0105,  0.0384]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef8dab",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5367f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.556338Z",
     "iopub.status.busy": "2022-07-31T02:32:56.556009Z",
     "iopub.status.idle": "2022-07-31T02:32:56.562475Z",
     "shell.execute_reply": "2022-07-31T02:32:56.561831Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2965c95",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd32641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:32:56.565379Z",
     "iopub.status.busy": "2022-07-31T02:32:56.565041Z",
     "iopub.status.idle": "2022-07-31T02:32:56.570481Z",
     "shell.execute_reply": "2022-07-31T02:32:56.569880Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092c4f8",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如说，如果你想在一个新的网络中使用之前网络的前两层，你该怎么做？\n",
    "1. 如何同时保存网络架构和参数？你会对架构加上什么限制？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f5d85",
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1839)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a218f2ce400cf959e6c98e2c271846438209855e89161ff99ad6bd03041409d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
